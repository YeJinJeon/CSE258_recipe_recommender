{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gzip\n",
    "from collections import defaultdict\n",
    "import math\n",
    "import scipy.optimize\n",
    "from sklearn import svm\n",
    "import numpy\n",
    "import string\n",
    "import random\n",
    "import string\n",
    "from sklearn import linear_model\n",
    "import pandas as pd\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1132367, 5)\n",
      "1132367\n",
      "Index(['user_id', 'recipe_id', 'date', 'rating', 'review'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "data_dir = \"C:/Users/samsung/UCSD/Fall22/CSE258/archive\"\n",
    "df_interactions = pd.read_csv(f\"{data_dir}/RAW_interactions.csv\")\n",
    "print(df_interactions.shape)\n",
    "print(len(df_interactions))\n",
    "print(df_interactions.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "226570\n",
      "231637\n"
     ]
    }
   ],
   "source": [
    "userIDs, itemIDs = {}, {}\n",
    "interactions = []\n",
    "\n",
    "for i in range(len(df_interactions)):\n",
    "    d = df_interactions.iloc[i]\n",
    "    u,i = d['user_id'], d['recipe_id']\n",
    "    if not u in userIDs: userIDs[u] = len(userIDs)\n",
    "    if not i in itemIDs: itemIDs[i] = len(itemIDs)\n",
    "    interactions.append((u,i,d['rating']))\n",
    "\n",
    "nUsers, nItems = len(userIDs), len(itemIDs)\n",
    "print(nUsers)\n",
    "print(nItems)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "y = [r for _,_,r in interactions]\n",
    "trainData, X_test, y_train, y_test = train_test_split(interactions, y, test_size=0.20, stratify=None, random_state=6752)\n",
    "validData = X_test[:int(len(X_test)*0.1)]\n",
    "testData = X_test[int(len(X_test)*0.1):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.411016039852804"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mu = sum([r for _,_,r in interactions]) / len(interactions)\n",
    "mu "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# user-item\n",
    "class LatentFactorModel(tf.keras.Model):\n",
    "    def __init__(self, mu, K, lamb_1, lamb_2):\n",
    "        super(LatentFactorModel, self).__init__()\n",
    "        # Initialize to average\n",
    "        self.alpha = tf.Variable(mu, dtype=tf.float32)\n",
    "        # Initialize to small random values\n",
    "        self.betaU = tf.Variable(tf.random.normal([len(userIDs)],stddev=0.001))\n",
    "        self.betaI = tf.Variable(tf.random.normal([len(itemIDs)],stddev=0.001))\n",
    "        self.gammaU = tf.Variable(tf.random.normal([len(userIDs),K],stddev=0.001))\n",
    "        self.gammaI = tf.Variable(tf.random.normal([len(itemIDs),K],stddev=0.001))\n",
    "        self.lamb_1 = lamb_1\n",
    "        self.lamb_2 = lamb_2\n",
    "\n",
    "    # Prediction for a single instance (useful for evaluation)\n",
    "    def predict(self, u, i):\n",
    "        p = self.alpha + self.betaU[u] + self.betaI[i] +\\\n",
    "            tf.tensordot(self.gammaU[u], self.gammaI[i], 1)\n",
    "        return p\n",
    "\n",
    "    # Regularizer\n",
    "    def reg(self):\n",
    "        return self.lamb_1 * tf.reduce_sum(self.betaU**2) +\\\n",
    "               self.lamb_1 * tf.reduce_sum(self.betaI**2) +\\\n",
    "               self.lamb_2 * tf.reduce_sum(self.gammaU**2) +\\\n",
    "               self.lamb_2 * tf.reduce_sum(self.gammaI**2)\n",
    "    \n",
    "    # Prediction for a sample of instances\n",
    "    def predictSample(self, sampleU, sampleI):\n",
    "        u = tf.convert_to_tensor(sampleU, dtype=tf.int32)\n",
    "        i = tf.convert_to_tensor(sampleI, dtype=tf.int32)\n",
    "        beta_u = tf.nn.embedding_lookup(self.betaU, u)\n",
    "        beta_i = tf.nn.embedding_lookup(self.betaI, i)\n",
    "        gamma_u = tf.nn.embedding_lookup(self.gammaU, u)\n",
    "        gamma_i = tf.nn.embedding_lookup(self.gammaI, i)\n",
    "        pred = self.alpha + beta_u + beta_i +\\\n",
    "               tf.reduce_sum(tf.multiply(gamma_u, gamma_i), 1)\n",
    "        return pred\n",
    "    \n",
    "    # Loss\n",
    "    def call(self, sampleU, sampleI, sampleR):\n",
    "        pred = self.predictSample(sampleU, sampleI)\n",
    "        r = tf.convert_to_tensor(sampleR, dtype=tf.float32)\n",
    "        return tf.nn.l2_loss(pred - r) / len(sampleR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "lamb_b = 0.000001\n",
    "lamb_g = 0.000001\n",
    "best_validMSE = 10\n",
    "K = 10\n",
    "lr = 0.01\n",
    "batch = 1024\n",
    "epoch = 10000\n",
    "\n",
    "model = LatentFactorModel(mu, 5, lamb_b, lamb_g)\n",
    "optimizer = tf.keras.optimizers.Adam(lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainingStep(interactions):\n",
    "    Nsamples = batch\n",
    "    with tf.GradientTape() as tape:\n",
    "        sampleU, sampleI, sampleR = [], [], []\n",
    "        for _ in range(Nsamples):\n",
    "            u,i,r = random.choice(interactions)\n",
    "            sampleU.append(userIDs[u])\n",
    "            sampleI.append(itemIDs[i])\n",
    "            sampleR.append(r)\n",
    "            \n",
    "        loss = model(sampleU,sampleI,sampleR)\n",
    "        loss += model.reg()\n",
    "    gradients = tape.gradient(loss, model.trainable_variables)\n",
    "    optimizer.apply_gradients((grad, var) for\n",
    "                              (grad, var) in zip(gradients, model.trainable_variables)\n",
    "                              if grad is not None)\n",
    "    return loss.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== K: 10 lamb_b: 1e-06 lamb_g: 1e-06=====\n",
      "iteration 261, objective = 0.8337669\n",
      "iteration 262, objective = 0.82722497\n",
      "iteration 263, objective = 0.7763771\n",
      "iteration 264, objective = 0.71063906\n",
      "iteration 265, objective = 0.7612779\n",
      "iteration 266, objective = 0.91031533\n",
      "iteration 267, objective = 0.7229339\n",
      "iteration 268, objective = 0.7174513\n",
      "iteration 269, objective = 0.8675228\n",
      "iteration 270, objective = 0.7732925\n",
      "iteration 270, validMSE = 1.5691668741777316\n",
      "iteration 271, objective = 0.65226334\n",
      "iteration 272, objective = 0.7569027\n",
      "iteration 273, objective = 0.82788914\n",
      "iteration 274, objective = 0.72874796\n",
      "iteration 275, objective = 0.96551806\n",
      "iteration 276, objective = 0.8921397\n",
      "iteration 277, objective = 0.81425583\n",
      "iteration 278, objective = 0.69947624\n",
      "iteration 279, objective = 0.81613743\n",
      "iteration 280, objective = 0.78229004\n",
      "iteration 280, validMSE = 1.5504047444219098\n",
      "iteration 281, objective = 0.7939201\n",
      "iteration 282, objective = 0.7015826\n",
      "iteration 283, objective = 0.6362364\n",
      "iteration 284, objective = 0.8640382\n",
      "iteration 285, objective = 0.9184116\n",
      "iteration 286, objective = 0.80448514\n",
      "iteration 287, objective = 0.9174954\n",
      "iteration 288, objective = 0.7002373\n",
      "iteration 289, objective = 0.74763614\n",
      "iteration 290, objective = 0.93002665\n",
      "iteration 290, validMSE = 1.5397782820116206\n",
      "iteration 291, objective = 0.75178206\n",
      "iteration 292, objective = 0.77084905\n",
      "iteration 293, objective = 0.81096816\n",
      "iteration 294, objective = 0.79156387\n",
      "iteration 295, objective = 0.7578653\n",
      "iteration 296, objective = 0.7708224\n",
      "iteration 297, objective = 0.7248955\n",
      "iteration 298, objective = 0.8071317\n",
      "iteration 299, objective = 0.80710554\n",
      "iteration 300, objective = 0.79854417\n",
      "iteration 300, validMSE = 1.5293868894985174\n",
      "iteration 301, objective = 0.81262314\n",
      "iteration 302, objective = 0.71604866\n",
      "iteration 303, objective = 0.8239959\n",
      "iteration 304, objective = 0.91400665\n",
      "iteration 305, objective = 0.7364749\n",
      "iteration 306, objective = 0.7996676\n",
      "iteration 307, objective = 0.7720346\n",
      "iteration 308, objective = 0.8497697\n",
      "iteration 309, objective = 0.751515\n",
      "iteration 310, objective = 0.84734625\n",
      "iteration 310, validMSE = 1.521389488056701\n",
      "iteration 311, objective = 0.7560242\n",
      "iteration 312, objective = 0.7614967\n",
      "iteration 313, objective = 0.75515604\n",
      "iteration 314, objective = 0.7332224\n",
      "iteration 315, objective = 0.7560663\n",
      "iteration 316, objective = 0.6933161\n",
      "iteration 317, objective = 0.801347\n",
      "iteration 318, objective = 0.67949206\n",
      "iteration 319, objective = 0.71355116\n",
      "iteration 320, objective = 0.8143937\n",
      "iteration 320, validMSE = 1.5145113665549335\n",
      "iteration 321, objective = 0.80144393\n",
      "iteration 322, objective = 0.6790465\n",
      "iteration 323, objective = 0.7870676\n",
      "iteration 324, objective = 0.7944646\n",
      "iteration 325, objective = 0.7674027\n",
      "iteration 326, objective = 0.77236795\n",
      "iteration 327, objective = 0.6516782\n",
      "iteration 328, objective = 0.77030814\n",
      "iteration 329, objective = 0.8443638\n",
      "iteration 330, objective = 0.7486472\n",
      "iteration 330, validMSE = 1.5080583790051088\n",
      "iteration 331, objective = 0.71613765\n",
      "iteration 332, objective = 0.80298024\n",
      "iteration 333, objective = 0.6775078\n",
      "iteration 334, objective = 0.67487425\n",
      "iteration 335, objective = 0.7459875\n",
      "iteration 336, objective = 0.7482383\n",
      "iteration 337, objective = 0.8199454\n",
      "iteration 338, objective = 0.8401335\n",
      "iteration 339, objective = 0.6625409\n",
      "iteration 340, objective = 0.7150316\n",
      "iteration 340, validMSE = 1.5029264632678692\n",
      "iteration 341, objective = 0.68281287\n",
      "iteration 342, objective = 0.6599386\n",
      "iteration 343, objective = 0.73013395\n",
      "iteration 344, objective = 0.8112164\n",
      "iteration 345, objective = 0.8574682\n",
      "iteration 346, objective = 0.69278574\n",
      "iteration 347, objective = 0.8634004\n",
      "iteration 348, objective = 0.7954149\n",
      "iteration 349, objective = 0.68451613\n",
      "iteration 350, objective = 0.7185911\n",
      "iteration 350, validMSE = 1.4982752715017074\n",
      "iteration 351, objective = 0.7044711\n",
      "iteration 352, objective = 0.79869175\n",
      "iteration 353, objective = 0.7679095\n",
      "iteration 354, objective = 0.78009766\n",
      "iteration 355, objective = 0.703867\n",
      "iteration 356, objective = 0.73764235\n",
      "iteration 357, objective = 0.7305738\n",
      "iteration 358, objective = 0.69327074\n",
      "iteration 359, objective = 0.6916657\n",
      "iteration 360, objective = 0.7596379\n",
      "iteration 360, validMSE = 1.494249991394371\n",
      "iteration 361, objective = 0.79491967\n",
      "iteration 362, objective = 0.665481\n",
      "iteration 363, objective = 0.7571138\n",
      "iteration 364, objective = 0.7780937\n",
      "iteration 365, objective = 0.7940618\n",
      "iteration 366, objective = 0.7962672\n",
      "iteration 367, objective = 0.76424956\n",
      "iteration 368, objective = 0.7907767\n",
      "iteration 369, objective = 0.78818107\n",
      "iteration 370, objective = 0.80771905\n",
      "iteration 370, validMSE = 1.4905284873516655\n",
      "iteration 371, objective = 0.78571117\n",
      "iteration 372, objective = 0.79027635\n",
      "iteration 373, objective = 0.7213809\n",
      "iteration 374, objective = 0.7453751\n",
      "iteration 375, objective = 0.7338846\n",
      "iteration 376, objective = 0.7689488\n",
      "iteration 377, objective = 0.6668799\n",
      "iteration 378, objective = 0.73277134\n",
      "iteration 379, objective = 0.6425017\n",
      "iteration 380, objective = 0.84257513\n",
      "iteration 380, validMSE = 1.4872536368990863\n",
      "iteration 381, objective = 0.6919585\n",
      "iteration 382, objective = 0.719288\n",
      "iteration 383, objective = 0.74640477\n",
      "iteration 384, objective = 0.6845226\n",
      "iteration 385, objective = 0.7699061\n",
      "iteration 386, objective = 0.72163093\n",
      "iteration 387, objective = 0.7396553\n",
      "iteration 388, objective = 0.8019257\n",
      "iteration 389, objective = 0.85522056\n",
      "iteration 390, objective = 0.87130135\n",
      "iteration 390, validMSE = 1.483616845324003\n",
      "iteration 391, objective = 0.6489923\n",
      "iteration 392, objective = 0.8224056\n",
      "iteration 393, objective = 0.73219085\n",
      "iteration 394, objective = 0.7563863\n",
      "iteration 395, objective = 0.6680367\n",
      "iteration 396, objective = 0.8924277\n",
      "iteration 397, objective = 0.83132833\n",
      "iteration 398, objective = 0.78795284\n",
      "iteration 399, objective = 0.7490506\n",
      "iteration 400, objective = 0.8279584\n",
      "iteration 400, validMSE = 1.4805720888434302\n",
      "iteration 401, objective = 0.75838834\n",
      "iteration 402, objective = 0.807921\n",
      "iteration 403, objective = 0.74226713\n",
      "iteration 404, objective = 0.7211528\n",
      "iteration 405, objective = 0.8269018\n",
      "iteration 406, objective = 0.6916355\n",
      "iteration 407, objective = 0.76437855\n",
      "iteration 408, objective = 0.69569504\n",
      "iteration 409, objective = 0.68908674\n",
      "iteration 410, objective = 0.78710985\n",
      "iteration 410, validMSE = 1.478126724538773\n",
      "iteration 411, objective = 0.68971395\n",
      "iteration 412, objective = 0.73629063\n",
      "iteration 413, objective = 0.7112322\n",
      "iteration 414, objective = 0.81102073\n",
      "iteration 415, objective = 0.84510124\n",
      "iteration 416, objective = 0.71766204\n",
      "iteration 417, objective = 0.63850296\n",
      "iteration 418, objective = 0.7026905\n",
      "iteration 419, objective = 0.7310854\n",
      "iteration 420, objective = 0.71078384\n",
      "iteration 420, validMSE = 1.4746311852808163\n",
      "iteration 421, objective = 0.71967864\n",
      "iteration 422, objective = 0.8533684\n",
      "iteration 423, objective = 0.76834565\n",
      "iteration 424, objective = 0.68953806\n",
      "iteration 425, objective = 0.6307701\n",
      "iteration 426, objective = 0.6064169\n",
      "iteration 427, objective = 0.70607615\n",
      "iteration 428, objective = 0.6452064\n",
      "iteration 429, objective = 0.791173\n",
      "iteration 430, objective = 0.6808258\n",
      "iteration 430, validMSE = 1.4722087855595782\n",
      "iteration 431, objective = 0.700243\n",
      "iteration 432, objective = 0.842765\n",
      "iteration 433, objective = 0.70946246\n",
      "iteration 434, objective = 0.80082256\n",
      "iteration 435, objective = 0.71224177\n",
      "iteration 436, objective = 0.70960903\n",
      "iteration 437, objective = 0.8041551\n",
      "iteration 438, objective = 0.7169329\n",
      "iteration 439, objective = 0.696826\n",
      "iteration 440, objective = 0.6660373\n",
      "iteration 440, validMSE = 1.4699874246415903\n",
      "iteration 441, objective = 0.7630431\n",
      "iteration 442, objective = 0.60504085\n",
      "iteration 443, objective = 0.87004536\n",
      "iteration 444, objective = 0.72962165\n",
      "iteration 445, objective = 0.69806\n",
      "iteration 446, objective = 0.69821256\n",
      "iteration 447, objective = 0.83228344\n",
      "iteration 448, objective = 0.6438258\n",
      "iteration 449, objective = 0.7642651\n",
      "iteration 450, objective = 0.6689319\n",
      "iteration 450, validMSE = 1.4678312077955118\n",
      "iteration 451, objective = 0.78219765\n",
      "iteration 452, objective = 0.70435643\n",
      "iteration 453, objective = 0.69821835\n",
      "iteration 454, objective = 0.6687223\n",
      "iteration 455, objective = 0.8899115\n",
      "iteration 456, objective = 0.70287406\n",
      "iteration 457, objective = 0.8027964\n",
      "iteration 458, objective = 0.6765745\n",
      "iteration 459, objective = 0.70577216\n",
      "iteration 460, objective = 0.75476307\n",
      "iteration 460, validMSE = 1.466437597793255\n",
      "iteration 461, objective = 0.7088634\n",
      "iteration 462, objective = 0.8716949\n",
      "iteration 463, objective = 0.7398562\n",
      "iteration 464, objective = 0.633466\n",
      "iteration 465, objective = 0.69091403\n",
      "iteration 466, objective = 0.7895439\n",
      "iteration 467, objective = 0.6210968\n",
      "iteration 468, objective = 0.7113656\n",
      "iteration 469, objective = 0.719244\n",
      "iteration 470, objective = 0.7226366\n",
      "iteration 470, validMSE = 1.4646214664079051\n",
      "iteration 471, objective = 0.8155157\n",
      "iteration 472, objective = 0.6552877\n",
      "iteration 473, objective = 0.6710614\n",
      "iteration 474, objective = 0.8039496\n",
      "iteration 475, objective = 0.6766908\n",
      "iteration 476, objective = 0.7916738\n",
      "iteration 477, objective = 0.72879916\n",
      "iteration 478, objective = 0.7827952\n",
      "iteration 479, objective = 0.74751616\n",
      "iteration 480, objective = 0.75583774\n",
      "iteration 480, validMSE = 1.4633060671705325\n",
      "iteration 481, objective = 0.6789213\n",
      "iteration 482, objective = 0.6640411\n",
      "iteration 483, objective = 0.77874565\n",
      "iteration 484, objective = 0.7790237\n",
      "iteration 485, objective = 0.6407789\n",
      "iteration 486, objective = 0.74872804\n",
      "iteration 487, objective = 0.7760943\n",
      "iteration 488, objective = 0.77583206\n",
      "iteration 489, objective = 0.7066668\n",
      "iteration 490, objective = 0.64394283\n",
      "iteration 490, validMSE = 1.4620053576172538\n",
      "iteration 491, objective = 0.5930185\n",
      "iteration 492, objective = 0.6869436\n",
      "iteration 493, objective = 0.8077286\n",
      "iteration 494, objective = 0.7040628\n",
      "iteration 495, objective = 0.7527564\n",
      "iteration 496, objective = 0.7513735\n",
      "iteration 497, objective = 0.79909277\n",
      "iteration 498, objective = 0.7684841\n",
      "iteration 499, objective = 0.717515\n",
      "iteration 500, objective = 0.704476\n",
      "iteration 500, validMSE = 1.4616271068558588\n",
      "iteration 501, objective = 0.83247656\n",
      "iteration 502, objective = 0.6862679\n",
      "iteration 503, objective = 0.7692201\n",
      "iteration 504, objective = 0.68555975\n",
      "iteration 505, objective = 0.686593\n",
      "iteration 506, objective = 0.8177902\n",
      "iteration 507, objective = 0.7107542\n",
      "iteration 508, objective = 0.76319927\n",
      "iteration 509, objective = 0.6475273\n",
      "iteration 510, objective = 0.691521\n",
      "iteration 510, validMSE = 1.4605450306802088\n",
      "iteration 511, objective = 0.65416\n",
      "iteration 512, objective = 0.8184439\n",
      "iteration 513, objective = 0.7526508\n",
      "iteration 514, objective = 0.8270422\n",
      "iteration 515, objective = 0.5924817\n",
      "iteration 516, objective = 0.6593573\n",
      "iteration 517, objective = 0.7776437\n",
      "iteration 518, objective = 0.70058787\n",
      "iteration 519, objective = 0.7720555\n",
      "iteration 520, objective = 0.7491454\n",
      "iteration 520, validMSE = 1.458902315281621\n",
      "iteration 521, objective = 0.798083\n",
      "iteration 522, objective = 0.741712\n",
      "iteration 523, objective = 0.659556\n",
      "iteration 524, objective = 0.6810694\n",
      "iteration 525, objective = 0.75715786\n",
      "iteration 526, objective = 0.6726347\n",
      "iteration 527, objective = 0.83486676\n",
      "iteration 528, objective = 0.6993844\n",
      "iteration 529, objective = 0.6649997\n",
      "iteration 530, objective = 0.7073734\n",
      "iteration 530, validMSE = 1.4578394641537495\n",
      "iteration 531, objective = 0.81082827\n",
      "iteration 532, objective = 0.5750615\n",
      "iteration 533, objective = 0.6590499\n",
      "iteration 534, objective = 0.7775992\n",
      "iteration 535, objective = 0.6413471\n",
      "iteration 536, objective = 0.74980867\n",
      "iteration 537, objective = 0.77289945\n",
      "iteration 538, objective = 0.6533765\n",
      "iteration 539, objective = 0.75847983\n",
      "iteration 540, objective = 0.80967146\n",
      "iteration 540, validMSE = 1.4563295263289273\n",
      "iteration 541, objective = 0.7464493\n",
      "iteration 542, objective = 0.6648305\n",
      "iteration 543, objective = 0.79156274\n",
      "iteration 544, objective = 0.7809035\n",
      "iteration 545, objective = 0.78317606\n",
      "iteration 546, objective = 0.7825311\n",
      "iteration 547, objective = 0.7341598\n",
      "iteration 548, objective = 0.82249236\n",
      "iteration 549, objective = 0.658325\n",
      "iteration 550, objective = 0.7392583\n",
      "iteration 550, validMSE = 1.4560872205840998\n",
      "iteration 551, objective = 0.7033853\n",
      "iteration 552, objective = 0.64039445\n",
      "iteration 553, objective = 0.56636477\n",
      "iteration 554, objective = 0.75894797\n",
      "iteration 555, objective = 0.75848466\n",
      "iteration 556, objective = 0.7043908\n",
      "iteration 557, objective = 0.7104846\n",
      "iteration 558, objective = 0.65778285\n",
      "iteration 559, objective = 0.72746366\n",
      "iteration 560, objective = 0.6704264\n",
      "iteration 560, validMSE = 1.4538181944000936\n",
      "iteration 561, objective = 0.7802532\n",
      "iteration 562, objective = 0.6655433\n",
      "iteration 563, objective = 0.8289082\n",
      "iteration 564, objective = 0.6956892\n",
      "iteration 565, objective = 0.6708547\n",
      "iteration 566, objective = 0.7260253\n",
      "iteration 567, objective = 0.7534322\n",
      "iteration 568, objective = 0.78745013\n",
      "iteration 569, objective = 0.675711\n",
      "iteration 570, objective = 0.73728406\n",
      "iteration 570, validMSE = 1.4529648595149294\n",
      "iteration 571, objective = 0.5618892\n",
      "iteration 572, objective = 0.68443084\n",
      "iteration 573, objective = 0.73601866\n",
      "iteration 574, objective = 0.7904784\n",
      "iteration 575, objective = 0.8757798\n",
      "iteration 576, objective = 0.74743444\n",
      "iteration 577, objective = 0.7649985\n",
      "iteration 578, objective = 0.6324522\n",
      "iteration 579, objective = 0.72519845\n",
      "iteration 580, objective = 0.6979536\n",
      "iteration 580, validMSE = 1.45340441929733\n",
      "iteration 581, objective = 0.6336533\n",
      "iteration 582, objective = 0.75789016\n",
      "iteration 583, objective = 0.66037595\n",
      "iteration 584, objective = 0.7744448\n",
      "iteration 585, objective = 0.71705866\n",
      "iteration 586, objective = 0.7794256\n",
      "iteration 587, objective = 0.6575792\n",
      "iteration 588, objective = 0.7959129\n",
      "iteration 589, objective = 0.69053847\n",
      "iteration 590, objective = 0.7701924\n",
      "iteration 590, validMSE = 1.4535705549815674\n",
      "iteration 591, objective = 0.66499144\n",
      "iteration 592, objective = 0.76454276\n",
      "iteration 593, objective = 0.6695581\n",
      "iteration 594, objective = 0.7154283\n",
      "iteration 595, objective = 0.71738976\n",
      "iteration 596, objective = 0.6542552\n",
      "iteration 597, objective = 0.6692952\n",
      "iteration 598, objective = 0.753362\n",
      "iteration 599, objective = 0.7627094\n",
      "iteration 600, objective = 0.70425224\n",
      "iteration 600, validMSE = 1.4531533208879794\n",
      "iteration 601, objective = 0.76809156\n",
      "iteration 602, objective = 0.6754322\n",
      "iteration 603, objective = 0.82401675\n",
      "iteration 604, objective = 0.71377265\n",
      "iteration 605, objective = 0.7271968\n",
      "iteration 606, objective = 0.6027353\n",
      "iteration 607, objective = 0.7078645\n",
      "iteration 608, objective = 0.8445273\n",
      "iteration 609, objective = 0.74027765\n",
      "iteration 610, objective = 0.7565039\n",
      "iteration 610, validMSE = 1.454392205320179\n",
      "iteration 611, objective = 0.63992256\n",
      "iteration 612, objective = 0.68514115\n",
      "iteration 613, objective = 0.67174304\n",
      "iteration 614, objective = 0.74542475\n",
      "iteration 615, objective = 0.7252726\n",
      "iteration 616, objective = 0.665255\n",
      "iteration 617, objective = 0.7580163\n",
      "iteration 618, objective = 0.7702647\n",
      "iteration 619, objective = 0.6240709\n",
      "iteration 620, objective = 0.7518528\n",
      "iteration 620, validMSE = 1.454087148522947\n",
      "iteration 621, objective = 0.5964954\n",
      "iteration 622, objective = 0.6592085\n",
      "iteration 623, objective = 0.6551182\n",
      "iteration 624, objective = 0.71324074\n",
      "iteration 625, objective = 0.6730781\n",
      "iteration 626, objective = 0.7227627\n",
      "iteration 627, objective = 0.6847437\n",
      "iteration 628, objective = 0.7036684\n",
      "iteration 629, objective = 0.6372295\n",
      "iteration 630, objective = 0.58182585\n",
      "iteration 630, validMSE = 1.4521606998171315\n",
      "iteration 631, objective = 0.6842644\n",
      "iteration 632, objective = 0.71830446\n",
      "iteration 633, objective = 0.6362951\n",
      "iteration 634, objective = 0.69699085\n",
      "iteration 635, objective = 0.71383345\n",
      "iteration 636, objective = 0.6136551\n",
      "iteration 637, objective = 0.5940461\n",
      "iteration 638, objective = 0.6355081\n",
      "iteration 639, objective = 0.8294133\n",
      "iteration 640, objective = 0.767925\n",
      "iteration 640, validMSE = 1.4521890419587533\n",
      "iteration 641, objective = 0.7965342\n",
      "iteration 642, objective = 0.7153676\n",
      "iteration 643, objective = 0.71998906\n",
      "iteration 644, objective = 0.6791262\n",
      "iteration 645, objective = 0.73037684\n",
      "iteration 646, objective = 0.7087284\n",
      "iteration 647, objective = 0.6517984\n",
      "iteration 648, objective = 0.7816352\n",
      "iteration 649, objective = 0.70321625\n",
      "iteration 650, objective = 0.68743175\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [20], line 14\u001b[0m\n\u001b[0;32m     12\u001b[0m predictions \u001b[39m=\u001b[39m []\n\u001b[0;32m     13\u001b[0m \u001b[39mfor\u001b[39;00m u,b,r \u001b[39min\u001b[39;00m validData:\n\u001b[1;32m---> 14\u001b[0m     pred \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mpredict(userIDs[u], itemIDs[b])\u001b[39m.\u001b[39mnumpy()\n\u001b[0;32m     15\u001b[0m     predictions\u001b[39m.\u001b[39mappend([pred, r])\n\u001b[0;32m     16\u001b[0m validMSE \u001b[39m=\u001b[39m \u001b[39msum\u001b[39m([(x\u001b[39m-\u001b[39my)\u001b[39m*\u001b[39m\u001b[39m*\u001b[39m\u001b[39m2\u001b[39m \u001b[39mfor\u001b[39;00m x,y \u001b[39min\u001b[39;00m predictions]) \u001b[39m/\u001b[39m \u001b[39mlen\u001b[39m(predictions)\n",
      "Cell \u001b[1;32mIn [17], line 18\u001b[0m, in \u001b[0;36mLatentFactorModel.predict\u001b[1;34m(self, u, i)\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mpredict\u001b[39m(\u001b[39mself\u001b[39m, u, i):\n\u001b[0;32m     17\u001b[0m     p \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39malpha \u001b[39m+\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbetaU[u] \u001b[39m+\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbetaI[i] \u001b[39m+\u001b[39m\\\n\u001b[1;32m---> 18\u001b[0m         tf\u001b[39m.\u001b[39;49mtensordot(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgammaU[u], \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgammaI[i], \u001b[39m1\u001b[39;49m)\n\u001b[0;32m     19\u001b[0m     \u001b[39mreturn\u001b[39;00m p\n",
      "File \u001b[1;32mc:\\Users\\samsung\\Anaconda3\\envs\\recipe\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py:201\u001b[0m, in \u001b[0;36madd_dispatch_support.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    199\u001b[0m \u001b[39m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[39;00m\n\u001b[0;32m    200\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 201\u001b[0m   \u001b[39mreturn\u001b[39;00m target(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m    202\u001b[0m \u001b[39mexcept\u001b[39;00m (\u001b[39mTypeError\u001b[39;00m, \u001b[39mValueError\u001b[39;00m):\n\u001b[0;32m    203\u001b[0m   \u001b[39m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[39;00m\n\u001b[0;32m    204\u001b[0m   \u001b[39m# TypeError, when given unexpected types.  So we need to catch both.\u001b[39;00m\n\u001b[0;32m    205\u001b[0m   result \u001b[39m=\u001b[39m dispatch(wrapper, args, kwargs)\n",
      "File \u001b[1;32mc:\\Users\\samsung\\Anaconda3\\envs\\recipe\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:4516\u001b[0m, in \u001b[0;36mtensordot\u001b[1;34m(a, b, axes, name)\u001b[0m\n\u001b[0;32m   4514\u001b[0m b \u001b[39m=\u001b[39m ops\u001b[39m.\u001b[39mconvert_to_tensor(b, name\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m   4515\u001b[0m a_axes, b_axes \u001b[39m=\u001b[39m _tensordot_axes(a, axes)\n\u001b[1;32m-> 4516\u001b[0m a_reshape, a_free_dims, a_free_dims_static \u001b[39m=\u001b[39m _tensordot_reshape(a, a_axes)\n\u001b[0;32m   4517\u001b[0m b_reshape, b_free_dims, b_free_dims_static \u001b[39m=\u001b[39m _tensordot_reshape(\n\u001b[0;32m   4518\u001b[0m     b, b_axes, \u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m   4519\u001b[0m ab_matmul \u001b[39m=\u001b[39m matmul(a_reshape, b_reshape)\n",
      "File \u001b[1;32mc:\\Users\\samsung\\Anaconda3\\envs\\recipe\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:4443\u001b[0m, in \u001b[0;36mtensordot.<locals>._tensordot_reshape\u001b[1;34m(a, axes, flipped)\u001b[0m\n\u001b[0;32m   4441\u001b[0m   a_trans \u001b[39m=\u001b[39m a\n\u001b[0;32m   4442\u001b[0m \u001b[39mif\u001b[39;00m a_trans\u001b[39m.\u001b[39mget_shape()\u001b[39m.\u001b[39mas_list() \u001b[39m!=\u001b[39m new_shape:\n\u001b[1;32m-> 4443\u001b[0m   reshaped_a \u001b[39m=\u001b[39m array_ops\u001b[39m.\u001b[39;49mreshape(a_trans, new_shape)\n\u001b[0;32m   4444\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   4445\u001b[0m   reshaped_a \u001b[39m=\u001b[39m a_trans\n",
      "File \u001b[1;32mc:\\Users\\samsung\\Anaconda3\\envs\\recipe\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py:201\u001b[0m, in \u001b[0;36madd_dispatch_support.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    199\u001b[0m \u001b[39m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[39;00m\n\u001b[0;32m    200\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 201\u001b[0m   \u001b[39mreturn\u001b[39;00m target(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m    202\u001b[0m \u001b[39mexcept\u001b[39;00m (\u001b[39mTypeError\u001b[39;00m, \u001b[39mValueError\u001b[39;00m):\n\u001b[0;32m    203\u001b[0m   \u001b[39m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[39;00m\n\u001b[0;32m    204\u001b[0m   \u001b[39m# TypeError, when given unexpected types.  So we need to catch both.\u001b[39;00m\n\u001b[0;32m    205\u001b[0m   result \u001b[39m=\u001b[39m dispatch(wrapper, args, kwargs)\n",
      "File \u001b[1;32mc:\\Users\\samsung\\Anaconda3\\envs\\recipe\\lib\\site-packages\\tensorflow\\python\\ops\\array_ops.py:195\u001b[0m, in \u001b[0;36mreshape\u001b[1;34m(tensor, shape, name)\u001b[0m\n\u001b[0;32m     59\u001b[0m \u001b[39m@tf_export\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mreshape\u001b[39m\u001b[39m\"\u001b[39m, v1\u001b[39m=\u001b[39m[\u001b[39m\"\u001b[39m\u001b[39mreshape\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mmanip.reshape\u001b[39m\u001b[39m\"\u001b[39m])\n\u001b[0;32m     60\u001b[0m \u001b[39m@dispatch\u001b[39m\u001b[39m.\u001b[39madd_dispatch_support\n\u001b[0;32m     61\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mreshape\u001b[39m(tensor, shape, name\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):  \u001b[39m# pylint: disable=redefined-outer-name\u001b[39;00m\n\u001b[0;32m     62\u001b[0m   \u001b[39mr\u001b[39m\u001b[39m\"\"\"Reshapes a tensor.\u001b[39;00m\n\u001b[0;32m     63\u001b[0m \n\u001b[0;32m     64\u001b[0m \u001b[39m  Given `tensor`, this operation returns a new `tf.Tensor` that has the same\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    193\u001b[0m \u001b[39m    A `Tensor`. Has the same type as `tensor`.\u001b[39;00m\n\u001b[0;32m    194\u001b[0m \u001b[39m  \"\"\"\u001b[39;00m\n\u001b[1;32m--> 195\u001b[0m   result \u001b[39m=\u001b[39m gen_array_ops\u001b[39m.\u001b[39;49mreshape(tensor, shape, name)\n\u001b[0;32m    196\u001b[0m   tensor_util\u001b[39m.\u001b[39mmaybe_set_static_shape(result, shape)\n\u001b[0;32m    197\u001b[0m   \u001b[39mreturn\u001b[39;00m result\n",
      "File \u001b[1;32mc:\\Users\\samsung\\Anaconda3\\envs\\recipe\\lib\\site-packages\\tensorflow\\python\\ops\\gen_array_ops.py:8227\u001b[0m, in \u001b[0;36mreshape\u001b[1;34m(tensor, shape, name)\u001b[0m\n\u001b[0;32m   8225\u001b[0m   \u001b[39mpass\u001b[39;00m\n\u001b[0;32m   8226\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 8227\u001b[0m   \u001b[39mreturn\u001b[39;00m reshape_eager_fallback(\n\u001b[0;32m   8228\u001b[0m       tensor, shape, name\u001b[39m=\u001b[39;49mname, ctx\u001b[39m=\u001b[39;49m_ctx)\n\u001b[0;32m   8229\u001b[0m \u001b[39mexcept\u001b[39;00m _core\u001b[39m.\u001b[39m_SymbolicException:\n\u001b[0;32m   8230\u001b[0m   \u001b[39mpass\u001b[39;00m  \u001b[39m# Add nodes to the TensorFlow graph.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\samsung\\Anaconda3\\envs\\recipe\\lib\\site-packages\\tensorflow\\python\\ops\\gen_array_ops.py:8252\u001b[0m, in \u001b[0;36mreshape_eager_fallback\u001b[1;34m(tensor, shape, name, ctx)\u001b[0m\n\u001b[0;32m   8250\u001b[0m _inputs_flat \u001b[39m=\u001b[39m [tensor, shape]\n\u001b[0;32m   8251\u001b[0m _attrs \u001b[39m=\u001b[39m (\u001b[39m\"\u001b[39m\u001b[39mT\u001b[39m\u001b[39m\"\u001b[39m, _attr_T, \u001b[39m\"\u001b[39m\u001b[39mTshape\u001b[39m\u001b[39m\"\u001b[39m, _attr_Tshape)\n\u001b[1;32m-> 8252\u001b[0m _result \u001b[39m=\u001b[39m _execute\u001b[39m.\u001b[39;49mexecute(\u001b[39mb\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mReshape\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m1\u001b[39;49m, inputs\u001b[39m=\u001b[39;49m_inputs_flat, attrs\u001b[39m=\u001b[39;49m_attrs,\n\u001b[0;32m   8253\u001b[0m                            ctx\u001b[39m=\u001b[39;49mctx, name\u001b[39m=\u001b[39;49mname)\n\u001b[0;32m   8254\u001b[0m \u001b[39mif\u001b[39;00m _execute\u001b[39m.\u001b[39mmust_record_gradient():\n\u001b[0;32m   8255\u001b[0m   _execute\u001b[39m.\u001b[39mrecord_gradient(\n\u001b[0;32m   8256\u001b[0m       \u001b[39m\"\u001b[39m\u001b[39mReshape\u001b[39m\u001b[39m\"\u001b[39m, _inputs_flat, _attrs, _result)\n",
      "File \u001b[1;32mc:\\Users\\samsung\\Anaconda3\\envs\\recipe\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:59\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     57\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m     58\u001b[0m   ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 59\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39;49mTFE_Py_Execute(ctx\u001b[39m.\u001b[39;49m_handle, device_name, op_name,\n\u001b[0;32m     60\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[0;32m     61\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     62\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "print(f\"===== K: {K} lamb_b: {lamb_b} lamb_g: {lamb_g}=====\")\n",
    "model = LatentFactorModel(mu, K, lamb_b, lamb_g) \n",
    "model.load_weights(f'./as1/batch1024_lr0.01_weights_K10_lambb1e-06_lambg1e-06/best_epoch260_model') #################3\n",
    "weight_dir = f'./as1/batch{batch}_lr{lr}_weights_K{K}_lambb{lamb_b}_lambg{lamb_g}'\n",
    "validMSE = 0\n",
    "best_validMSE = 10\n",
    "valid_error = []\n",
    "for i in range(261, 260+epoch):\n",
    "    obj = trainingStep(trainData)\n",
    "    print(\"iteration \" + str(i) + \", objective = \" + str(obj))\n",
    "    if i % 10 == 0 and i > 0: \n",
    "        predictions = []\n",
    "        for u,b,r in validData:\n",
    "            pred = model.predict(userIDs[u], itemIDs[b]).numpy()\n",
    "            predictions.append([pred, r])\n",
    "        validMSE = sum([(x-y)**2 for x,y in predictions]) / len(predictions)\n",
    "        valid_error.append(validMSE)\n",
    "        if validMSE < best_validMSE:\n",
    "            model.save_weights(f'{weight_dir}/best_epoch{i}_model', save_format='tf')\n",
    "        print(\"iteration \" + str(i) + \", validMSE = \" + str(validMSE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2000"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testData = X_test[int(len(X_test)*0.1):][-2000:]\n",
    "len(testData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.468220046792608\n",
      "2000\n"
     ]
    }
   ],
   "source": [
    "# test\n",
    "# lamb 0.01(epoch250) -> 1.5911313\n",
    "# lambb 0.01 / lambg 0.001 -> 1.5906503355443455\n",
    "loaded_model = LatentFactorModel(mu, 10, lamb_b, lamb_g)\n",
    "loaded_model.load_weights(f'./as1/batch1024_lr0.01_weights_K10_lambb1e-06_lambg1e-06/best_epoch250_model')\n",
    "predictions = []\n",
    "for u,b,r,_,_,_ in testData:\n",
    "    pred = loaded_model.predict(userIDs[u], itemIDs[b]).numpy()\n",
    "    predictions.append([pred, r])\n",
    "testMSE = sum([(x-y)**2 for x,y in predictions]) / len(predictions)\n",
    "print(testMSE)\n",
    "\n",
    "print(len(predictions))\n",
    "# open the file in the write mode\n",
    "with open('./lfm_result.csv', 'w') as f:\n",
    "    # create the csv writer\n",
    "    for p,t in predictions:\n",
    "        f.writelines(f\"{p},{t}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Latent Factor Model with Side Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Generate Train Data with Side Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"C:/Users/samsung/UCSD/Fall22/CSE258/archive\"\n",
    "df_recipes = pd.read_csv(f\"{data_dir}/RAW_recipes.csv\")\n",
    "df_interactions = pd.read_csv(f\"{data_dir}/RAW_interactions.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.merge(df_recipes, df_interactions, right_on='recipe_id',left_on='id')\n",
    "data[['calories','total fat','sugar','sodium','protein','saturated fat','carbohydrates']] = data.nutrition.str.split(\",\",expand=True) \n",
    "data['calories'] = data['calories'].apply(lambda x: x.replace(\"[\" ,\"\"))\n",
    "data['carbohydrates'] = data['carbohydrates'].apply(lambda x: x.replace(\"]\" ,\"\"))\n",
    "data[['calories','total fat','sugar','sodium','protein','saturated fat','carbohydrates']] =  data[['calories','total fat','sugar','sodium','protein','saturated fat','carbohydrates']].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "226570\n",
      "231637\n"
     ]
    }
   ],
   "source": [
    "userIDs, itemIDs = {}, {}\n",
    "interactions_v2 = []\n",
    "\n",
    "for i in range(len(data)):\n",
    "    d = data.iloc[i]\n",
    "    u,i = d['user_id'], d['recipe_id']\n",
    "    if not u in userIDs: userIDs[u] = len(userIDs)\n",
    "    if not i in itemIDs: itemIDs[i] = len(itemIDs)\n",
    "    calories = d['calories']\n",
    "    minutes = d['minutes']\n",
    "    steps = d['n_steps']\n",
    "    interactions_v2.append((u,i,d['rating'],calories,minutes,steps))\n",
    "\n",
    "nUsers, nItems = len(userIDs), len(itemIDs)\n",
    "print(nUsers)\n",
    "print(nItems)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "trainData, X_test = train_test_split(interactions_v2, test_size=0.20, stratify=None, random_state=6752)\n",
    "validData = X_test[:int(len(X_test)*0.1)]\n",
    "testData = X_test[int(len(X_test)*0.1):]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Latent Factor Model with side features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "calories = set()\n",
    "for i in range(len(data)):\n",
    "    d = data.iloc[i]\n",
    "    calories.add(d['calories'])\n",
    "q1 = np.percentile(list(calories),25)\n",
    "q2 = np.percentile(list(calories),50)\n",
    "q3 = np.percentile(list(calories),75)\n",
    "q4 = np.percentile(list(calories),100)\n",
    "\n",
    "def convert_cal(x):\n",
    "    if x <= q1:\n",
    "        return 0\n",
    "    elif x > q1 and x <= q2:\n",
    "        return 1\n",
    "    elif x > q2 and x <= q3:\n",
    "        return 2\n",
    "    elif x > q3 and x <= q4:\n",
    "        return 3\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# user-item-calories\n",
    "class LatentFactorModel_calories(tf.keras.Model):\n",
    "    def __init__(self, mu, K, lamb_1, lamb_2):\n",
    "        super(LatentFactorModel_calories, self).__init__()\n",
    "        # Initialize to average\n",
    "        self.alpha = tf.Variable(mu, dtype=tf.float32)\n",
    "        # Initialize to small random values\n",
    "        self.betaU = tf.Variable(tf.random.normal([len(userIDs)],stddev=0.001))\n",
    "        self.betaI = tf.Variable(tf.random.normal([len(itemIDs)],stddev=0.001))\n",
    "        self.betaCal = tf.Variable(tf.random.normal([4],stddev=0.001))\n",
    "        self.gammaU = tf.Variable(tf.random.normal([len(userIDs),K],stddev=0.001))\n",
    "        self.gammaI = tf.Variable(tf.random.normal([len(itemIDs),K],stddev=0.001))\n",
    "        self.gammaCal = tf.Variable(tf.random.normal([4,K],stddev=0.001))\n",
    "        self.lamb_1 = lamb_1\n",
    "        self.lamb_2 = lamb_2\n",
    "\n",
    "    # Prediction for a single instance (useful for evaluation)\n",
    "    def predict(self, u, i, cal):\n",
    "        cal = int(cal)\n",
    "        cal_class = convert_cal(cal)\n",
    "        p = self.alpha + self.betaU[u] + self.betaI[i] + cal*self.betaCal[cal_class] +\\\n",
    "            tf.tensordot(self.gammaU[u], self.gammaI[i], 1) +\\\n",
    "            tf.tensordot(self.gammaI[u], self.gammaCal[cal_class], 1)  \n",
    "        return p\n",
    "\n",
    "    # Regularizer\n",
    "    def reg(self):\n",
    "            return self.lamb_1 * tf.reduce_sum(self.betaU**2) +\\\n",
    "               self.lamb_1 * tf.reduce_sum(self.betaI**2) +\\\n",
    "               self.lamb_1 * tf.reduce_sum(self.betaCal**2) +\\\n",
    "               self.lamb_2 * tf.reduce_sum(self.gammaU**2) +\\\n",
    "               self.lamb_2 * tf.reduce_sum(self.gammaI**2) +\\\n",
    "               self.lamb_2 * tf.reduce_sum(self.gammaCal**2)   \n",
    "    \n",
    "    # Prediction for a sample of instances\n",
    "    def predictSample(self, sampleU, sampleI, sampleCal):\n",
    "        u = tf.convert_to_tensor(sampleU, dtype=tf.int32)\n",
    "        i = tf.convert_to_tensor(sampleI, dtype=tf.int32)\n",
    "        cal = tf.convert_to_tensor(sampleCal, dtype=tf.float32)\n",
    "        cal_class = [convert_cal(c) for c in sampleCal]\n",
    "        cal_calss = tf.convert_to_tensor(cal_class, dtype=tf.int32)\n",
    "        beta_u = tf.nn.embedding_lookup(self.betaU, u)\n",
    "        beta_i = tf.nn.embedding_lookup(self.betaI, i)\n",
    "        beta_cal = tf.nn.embedding_lookup(self.betaCal, cal_class)\n",
    "        gamma_u = tf.nn.embedding_lookup(self.gammaU, u)\n",
    "        gamma_i = tf.nn.embedding_lookup(self.gammaI, i)\n",
    "        gamma_cal = tf.nn.embedding_lookup(self.gammaCal, cal_class)\n",
    "        pred = self.alpha + beta_u + beta_i + cal*beta_cal +\\\n",
    "               tf.reduce_sum(tf.multiply(gamma_u, gamma_i), 1) +\\\n",
    "               tf.reduce_sum(cal*tf.multiply(gamma_i, gamma_cal), 1)\n",
    "        return pred\n",
    "    \n",
    "    # Loss\n",
    "    def call(self, sampleU, sampleI, sampleR, sampleCal):\n",
    "        pred = self.predictSample(sampleU, sampleI, sampleCal)\n",
    "        r = tf.convert_to_tensor(sampleR, dtype=tf.float32)\n",
    "        return tf.nn.l2_loss(pred - r) / len(sampleR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainingStep(interactions):\n",
    "    Nsamples = batch\n",
    "    with tf.GradientTape() as tape:\n",
    "        sampleU, sampleI, sampleR, sampleCal = [], [], [], []\n",
    "        for _ in range(Nsamples):\n",
    "            u,i,r,cal,_,_, = random.choice(interactions)\n",
    "            sampleU.append(userIDs[u])\n",
    "            sampleI.append(itemIDs[i])\n",
    "            sampleR.append(r)\n",
    "            sampleCal.append(cal)\n",
    "            \n",
    "        loss = model(sampleU,sampleI,sampleR,sampleCal)\n",
    "        loss += model.reg()\n",
    "    gradients = tape.gradient(loss, model.trainable_variables)\n",
    "    optimizer.apply_gradients((grad, var) for\n",
    "                              (grad, var) in zip(gradients, model.trainable_variables)\n",
    "                              if grad is not None)\n",
    "    return loss.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "lamb_b = 0.000001\n",
    "lamb_g = 0.000001\n",
    "best_validMSE = 10\n",
    "K = 10\n",
    "lr = 0.01\n",
    "batch = 1024\n",
    "epoch = 10000\n",
    "\n",
    "model = LatentFactorModel_calories(mu, K, lamb_b, lamb_g)\n",
    "optimizer = tf.keras.optimizers.Adam(lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== K: 10 lamb_b: 1e-06 lamb_g: 1e-06=====\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "Incompatible shapes: [1024] vs. [1024,10] [Op:Mul]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [93], line 8\u001b[0m\n\u001b[0;32m      6\u001b[0m valid_error \u001b[39m=\u001b[39m []\n\u001b[0;32m      7\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(epoch):\n\u001b[1;32m----> 8\u001b[0m     obj \u001b[39m=\u001b[39m trainingStep(trainData)\n\u001b[0;32m      9\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39miteration \u001b[39m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m \u001b[39mstr\u001b[39m(i) \u001b[39m+\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m, objective = \u001b[39m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m \u001b[39mstr\u001b[39m(obj))\n\u001b[0;32m     10\u001b[0m     \u001b[39mif\u001b[39;00m i \u001b[39m%\u001b[39m \u001b[39m10\u001b[39m \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m \u001b[39mand\u001b[39;00m i \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m: \n",
      "Cell \u001b[1;32mIn [88], line 12\u001b[0m, in \u001b[0;36mtrainingStep\u001b[1;34m(interactions)\u001b[0m\n\u001b[0;32m      9\u001b[0m         sampleR\u001b[39m.\u001b[39mappend(r)\n\u001b[0;32m     10\u001b[0m         sampleCal\u001b[39m.\u001b[39mappend(cal)\n\u001b[1;32m---> 12\u001b[0m     loss \u001b[39m=\u001b[39m model(sampleU,sampleI,sampleR,sampleCal)\n\u001b[0;32m     13\u001b[0m     loss \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mreg()\n\u001b[0;32m     14\u001b[0m gradients \u001b[39m=\u001b[39m tape\u001b[39m.\u001b[39mgradient(loss, model\u001b[39m.\u001b[39mtrainable_variables)\n",
      "File \u001b[1;32mc:\\Users\\samsung\\Anaconda3\\envs\\recipe\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py:985\u001b[0m, in \u001b[0;36mLayer.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    982\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_build(inputs)\n\u001b[0;32m    984\u001b[0m \u001b[39mwith\u001b[39;00m ops\u001b[39m.\u001b[39menable_auto_cast_variables(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compute_dtype_object):\n\u001b[1;32m--> 985\u001b[0m   outputs \u001b[39m=\u001b[39m call_fn(inputs, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m    987\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_activity_regularizer:\n\u001b[0;32m    988\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_handle_activity_regularization(inputs, outputs)\n",
      "Cell \u001b[1;32mIn [91], line 55\u001b[0m, in \u001b[0;36mLatentFactorModel_calories.call\u001b[1;34m(self, sampleU, sampleI, sampleR, sampleCal)\u001b[0m\n\u001b[0;32m     54\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcall\u001b[39m(\u001b[39mself\u001b[39m, sampleU, sampleI, sampleR, sampleCal):\n\u001b[1;32m---> 55\u001b[0m     pred \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpredictSample(sampleU, sampleI, sampleCal)\n\u001b[0;32m     56\u001b[0m     r \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mconvert_to_tensor(sampleR, dtype\u001b[39m=\u001b[39mtf\u001b[39m.\u001b[39mfloat32)\n\u001b[0;32m     57\u001b[0m     \u001b[39mreturn\u001b[39;00m tf\u001b[39m.\u001b[39mnn\u001b[39m.\u001b[39ml2_loss(pred \u001b[39m-\u001b[39m r) \u001b[39m/\u001b[39m \u001b[39mlen\u001b[39m(sampleR)\n",
      "Cell \u001b[1;32mIn [91], line 50\u001b[0m, in \u001b[0;36mLatentFactorModel_calories.predictSample\u001b[1;34m(self, sampleU, sampleI, sampleCal)\u001b[0m\n\u001b[0;32m     46\u001b[0m gamma_i \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mnn\u001b[39m.\u001b[39membedding_lookup(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgammaI, i)\n\u001b[0;32m     47\u001b[0m gamma_cal \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mnn\u001b[39m.\u001b[39membedding_lookup(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgammaCal, cal_class)\n\u001b[0;32m     48\u001b[0m pred \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39malpha \u001b[39m+\u001b[39m beta_u \u001b[39m+\u001b[39m beta_i \u001b[39m+\u001b[39m cal\u001b[39m*\u001b[39mbeta_cal \u001b[39m+\u001b[39m\\\n\u001b[0;32m     49\u001b[0m        tf\u001b[39m.\u001b[39mreduce_sum(tf\u001b[39m.\u001b[39mmultiply(gamma_u, gamma_i), \u001b[39m1\u001b[39m) \u001b[39m+\u001b[39m\\\n\u001b[1;32m---> 50\u001b[0m        tf\u001b[39m.\u001b[39mreduce_sum(cal\u001b[39m*\u001b[39;49mtf\u001b[39m.\u001b[39;49mmultiply(gamma_i, gamma_cal), \u001b[39m1\u001b[39m)\n\u001b[0;32m     51\u001b[0m \u001b[39mreturn\u001b[39;00m pred\n",
      "File \u001b[1;32mc:\\Users\\samsung\\Anaconda3\\envs\\recipe\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:1125\u001b[0m, in \u001b[0;36m_OverrideBinaryOperatorHelper.<locals>.binary_op_wrapper\u001b[1;34m(x, y)\u001b[0m\n\u001b[0;32m   1123\u001b[0m \u001b[39mwith\u001b[39;00m ops\u001b[39m.\u001b[39mname_scope(\u001b[39mNone\u001b[39;00m, op_name, [x, y]) \u001b[39mas\u001b[39;00m name:\n\u001b[0;32m   1124\u001b[0m   \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 1125\u001b[0m     \u001b[39mreturn\u001b[39;00m func(x, y, name\u001b[39m=\u001b[39;49mname)\n\u001b[0;32m   1126\u001b[0m   \u001b[39mexcept\u001b[39;00m (\u001b[39mTypeError\u001b[39;00m, \u001b[39mValueError\u001b[39;00m) \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m   1127\u001b[0m     \u001b[39m# Even if dispatching the op failed, the RHS may be a tensor aware\u001b[39;00m\n\u001b[0;32m   1128\u001b[0m     \u001b[39m# object that can implement the operator with knowledge of itself\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1131\u001b[0m     \u001b[39m# original error from the LHS, because it may be more\u001b[39;00m\n\u001b[0;32m   1132\u001b[0m     \u001b[39m# informative.\u001b[39;00m\n\u001b[0;32m   1133\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(\u001b[39mtype\u001b[39m(y), \u001b[39m\"\u001b[39m\u001b[39m__r\u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m__\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m op_name):\n",
      "File \u001b[1;32mc:\\Users\\samsung\\Anaconda3\\envs\\recipe\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:1457\u001b[0m, in \u001b[0;36m_mul_dispatch\u001b[1;34m(x, y, name)\u001b[0m\n\u001b[0;32m   1455\u001b[0m   \u001b[39mreturn\u001b[39;00m sparse_tensor\u001b[39m.\u001b[39mSparseTensor(y\u001b[39m.\u001b[39mindices, new_vals, y\u001b[39m.\u001b[39mdense_shape)\n\u001b[0;32m   1456\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m-> 1457\u001b[0m   \u001b[39mreturn\u001b[39;00m multiply(x, y, name\u001b[39m=\u001b[39;49mname)\n",
      "File \u001b[1;32mc:\\Users\\samsung\\Anaconda3\\envs\\recipe\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py:201\u001b[0m, in \u001b[0;36madd_dispatch_support.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    199\u001b[0m \u001b[39m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[39;00m\n\u001b[0;32m    200\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 201\u001b[0m   \u001b[39mreturn\u001b[39;00m target(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m    202\u001b[0m \u001b[39mexcept\u001b[39;00m (\u001b[39mTypeError\u001b[39;00m, \u001b[39mValueError\u001b[39;00m):\n\u001b[0;32m    203\u001b[0m   \u001b[39m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[39;00m\n\u001b[0;32m    204\u001b[0m   \u001b[39m# TypeError, when given unexpected types.  So we need to catch both.\u001b[39;00m\n\u001b[0;32m    205\u001b[0m   result \u001b[39m=\u001b[39m dispatch(wrapper, args, kwargs)\n",
      "File \u001b[1;32mc:\\Users\\samsung\\Anaconda3\\envs\\recipe\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:509\u001b[0m, in \u001b[0;36mmultiply\u001b[1;34m(x, y, name)\u001b[0m\n\u001b[0;32m    463\u001b[0m \u001b[39m@tf_export\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mmath.multiply\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mmultiply\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    464\u001b[0m \u001b[39m@dispatch\u001b[39m\u001b[39m.\u001b[39madd_dispatch_support\n\u001b[0;32m    465\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mmultiply\u001b[39m(x, y, name\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m    466\u001b[0m   \u001b[39m\"\"\"Returns an element-wise x * y.\u001b[39;00m\n\u001b[0;32m    467\u001b[0m \n\u001b[0;32m    468\u001b[0m \u001b[39m  For example:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    506\u001b[0m \u001b[39m   * InvalidArgumentError: When `x` and `y` have incomptatible shapes or types.\u001b[39;00m\n\u001b[0;32m    507\u001b[0m \u001b[39m  \"\"\"\u001b[39;00m\n\u001b[1;32m--> 509\u001b[0m   \u001b[39mreturn\u001b[39;00m gen_math_ops\u001b[39m.\u001b[39;49mmul(x, y, name)\n",
      "File \u001b[1;32mc:\\Users\\samsung\\Anaconda3\\envs\\recipe\\lib\\site-packages\\tensorflow\\python\\ops\\gen_math_ops.py:6165\u001b[0m, in \u001b[0;36mmul\u001b[1;34m(x, y, name)\u001b[0m\n\u001b[0;32m   6163\u001b[0m   \u001b[39mreturn\u001b[39;00m _result\n\u001b[0;32m   6164\u001b[0m \u001b[39mexcept\u001b[39;00m _core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m-> 6165\u001b[0m   _ops\u001b[39m.\u001b[39;49mraise_from_not_ok_status(e, name)\n\u001b[0;32m   6166\u001b[0m \u001b[39mexcept\u001b[39;00m _core\u001b[39m.\u001b[39m_FallbackException:\n\u001b[0;32m   6167\u001b[0m   \u001b[39mpass\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\samsung\\Anaconda3\\envs\\recipe\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py:6843\u001b[0m, in \u001b[0;36mraise_from_not_ok_status\u001b[1;34m(e, name)\u001b[0m\n\u001b[0;32m   6841\u001b[0m message \u001b[39m=\u001b[39m e\u001b[39m.\u001b[39mmessage \u001b[39m+\u001b[39m (\u001b[39m\"\u001b[39m\u001b[39m name: \u001b[39m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m name \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m   6842\u001b[0m \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m-> 6843\u001b[0m six\u001b[39m.\u001b[39;49mraise_from(core\u001b[39m.\u001b[39;49m_status_to_exception(e\u001b[39m.\u001b[39;49mcode, message), \u001b[39mNone\u001b[39;49;00m)\n",
      "File \u001b[1;32m<string>:3\u001b[0m, in \u001b[0;36mraise_from\u001b[1;34m(value, from_value)\u001b[0m\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m: Incompatible shapes: [1024] vs. [1024,10] [Op:Mul]"
     ]
    }
   ],
   "source": [
    "print(f\"===== K: {K} lamb_b: {lamb_b} lamb_g: {lamb_g}=====\")\n",
    "model = LatentFactorModel_calories(mu, K, lamb_b, lamb_g)\n",
    "weight_dir = f'./as4/batch{batch}_lr{lr}_weights_K{K}_lambb{lamb_b}_lambg{lamb_g}'\n",
    "validMSE = 0\n",
    "best_validMSE = 10\n",
    "valid_error = []\n",
    "for i in range(epoch):\n",
    "    obj = trainingStep(trainData)\n",
    "    print(\"iteration \" + str(i) + \", objective = \" + str(obj))\n",
    "    if i % 10 == 0 and i > 0: \n",
    "        predictions = []\n",
    "        for u,b,r,cal,_,_ in validData:\n",
    "            pred = model.predict(userIDs[u], itemIDs[b], cal).numpy()\n",
    "            predictions.append([pred, r])\n",
    "        validMSE = sum([(x-y)**2 for x,y in predictions]) / len(predictions)\n",
    "        valid_error.append(validMSE)\n",
    "        if validMSE < best_validMSE:\n",
    "            model.save_weights(f'{weight_dir}/best_epoch{i}_model', save_format='tf')\n",
    "        print(\"iteration \" + str(i) + \", validMSE = \" + str(validMSE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.5566137961189648\n",
      "2000\n"
     ]
    }
   ],
   "source": [
    "# test\n",
    "# lamb 0.01(epoch250) -> 1.5911313\n",
    "# lambb 0.01 / lambg 0.001 -> 1.5906503355443455\n",
    "loaded_model = LatentFactorModel_calories(mu, 10, lamb_b, lamb_g)\n",
    "loaded_model.load_weights(f'./as3/batch1024_lr0.01_weights_K10_lambb1e-06_lambg1e-06/best_epoch250_model')\n",
    "predictions = []\n",
    "for u,b,r,cal,_,_ in testData:\n",
    "    pred = loaded_model.predict(userIDs[u], itemIDs[b], convert_cal(cal)).numpy()\n",
    "    predictions.append([pred, r])\n",
    "testMSE = sum([(x-y)**2 for x,y in predictions]) / len(predictions)\n",
    "print(testMSE)\n",
    "print(len(predictions))\n",
    "\n",
    "# open the file in the write mode\n",
    "with open('./lfm_calories_result.csv', 'w') as f:\n",
    "    # create the csv writer\n",
    "    for p,t in predictions:\n",
    "        f.writelines(f\"{p},{t}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.6184779944859702\n",
      "2000\n"
     ]
    }
   ],
   "source": [
    "# test\n",
    "# lamb 0.01(epoch250) -> 1.5911313\n",
    "# lambb 0.01 / lambg 0.001 -> 1.5906503355443455\n",
    "loaded_model = LatentFactorModel_calories(mu, 10, lamb_b, lamb_g)\n",
    "loaded_model.load_weights(f'./as2/batch1024_lr0.01_weights_K10_lambb1e-06_lambg1e-06/best_epoch250_model')\n",
    "predictions = []\n",
    "for u,b,r,cal,_,_ in testData:\n",
    "    pred = loaded_model.predict(userIDs[u], itemIDs[b], convert_cal(cal)).numpy()\n",
    "    predictions.append([pred, r])\n",
    "testMSE = sum([(x-y)**2 for x,y in predictions]) / len(predictions)\n",
    "print(testMSE)\n",
    "print(len(predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "fig, axes = plt.subplots(ncols=1, figsize=(8, 8))\n",
    "\n",
    "x = np.arange(1, n_iter) * step_size\n",
    "with plt.style.context('fivethirtyeight'):\n",
    "    axes.plot(x, rmse_train, label='MSE-train', color='b')\n",
    "    axes.plot(x, rmse_test, label='MSE-test', color='r')\n",
    "axes.set_ylabel('MSE', color='r')\n",
    "axes.legend()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "69c9df83c9beb7eb367d45a743bebb10bf028babe0247f6b5c4e1ec81fa6b650"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
